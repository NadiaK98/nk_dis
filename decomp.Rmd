---
title: "Decomp"
author: "Nads"
date: "25/07/2021"
output: html_document
---

```{r load_data, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(dplyr)
library(readr)
library(janitor)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(readxl)
library(tsibble)
library(forecast)
library(sf)
library(ggspatial)
library(ggmap)
library(knitr)
library(sjPlot)
library(tmap)
library(sp)
library(spdep)

## data ----------------------------------------------------------------------------------------------------

calls <- read_csv("Z:\\n8_data_v2.csv.gz") %>% clean_names()
missing <- subset(calls, incident_type == "Missing Person")
missing <- subset(missing, select = -c(4, 6, 9, 10, 15))

 #add lsoa 
name_code <- read_csv("data/Lower_Layer_Super_Output_Areas_December_2011_Names_and_Codes_in_England_and_Wales.csv") %>%
  clean_names() %>%
  select(lsoa11cd, lsoa11nm)
missing <- left_join(missing, name_code, by = c("lsoa" = "lsoa11nm"))

 # add system changes 
 # Add dummy variables
missing <- missing %>% 
  mutate(
    # Dummy for change from old to new call-handling system
    new_system = incident_date_time > yearweek(ymd("2017-06-03")),
    # Dummy for changes in practice after adverse HMIC call-handling report
    hmic_changes = incident_date_time > yearweek(ymd("2017-05-15")), 
    # Dummy for bank holiday 
    bank_holiday = incident_date_time %in% yearweek(as_date(timeDate::holidayLONDON(year = 2015:2020))))




## final classification -----------------------------------------------------------------------------------
minor_cat <- missing %>%  
  #get rid of those not classed as missing or abondened
  count(final_classification_description_1) %>% 
  filter(n < 1500) %>%
  pull(final_classification_description_1)

missing <- missing %>% 
  mutate(
    final_class = case_when(
      final_classification_description_1 %in% c(
        "Missing Person", 
        "MISSING PERSON"
      ) ~ "Missing Person",
      final_classification_description_1 %in% c(
        "Absent Person", 
        "ABSENT PERSON"
      ) ~ "Absent Person",
      final_classification_description_1 %in% minor_cat ~ "Other",
      TRUE ~ final_classification_description_1
    ))


## origin -------------------------------------------------------------------------

minor_categories2 <- missing %>% 
  count(call_origin) %>% 
  filter(n < 20) %>%   # basially ANPR
  pull(call_origin)
      
missing <- missing %>% 
  mutate(
    call_origin = case_when(
      call_origin %in% c(
        "Alarm Company", 
        "Email (to Public Contact Mailbox)",
        "Helpdesk",
        "Public Non Emergency (inc. Door Phones and PCPs)",
        "Single Online Home",
        "ANPR",
        "Social Media"
      ) ~ "public non-emergency",
      call_origin == "Other Emergency Services (inc. Other Forces)" ~
        "other emergency services",
      call_origin == "Police Generated (inc. Call Sign / Collar Numbers)" ~
        "police generated",
      #call_origin %in% minor_categories2 ~ "other",
      call_origin == "Unknown Choice List Value" | is.na(call_origin) ~ 
        NA_character_,
      TRUE ~ call_origin
    ))
      

  
## Grade change -------------------------------------------------------------

missing <- missing %>% 
  mutate(initial_grade_of_response = str_remove_all(initial_grade_of_response, "Grade"))
missing <- missing %>% 
  mutate(current_response_grade = str_remove_all(current_response_grade, "Grade"))
missing <- missing %>%
  mutate("Grade_Change" = ifelse(initial_grade_of_response == current_response_grade, "True", "False"))

  

# Attended -----------------------------------------------------------------
missing$attended <- case_when(missing$attended_flag == 1 ~ "Yes", 
                             missing$attended_flag == 0 ~ "No", 
                             TRUE ~ NA_character_)

# filter attended only 
attended_missing <- missing %>% filter(attended == "Yes")



# Pandemic ------------------------------------------------------------------
library(openair)

x <- missing
x$date <- as.Date(x$incident_date_time, format = "%Y-%m-%d")


pre <- selectByDate(x, 
                    start = "2015-01-01", 
                    end = "2019-12-31")

covid <- selectByDate(x, 
                      start = "2020-01-01", 
                      end = "2020-12-31")

```






#### Basic Time Series of MP 2015:2020 

```{r plot}
missing %>%
  mutate(week = as_date(yearweek(incident_date_time))) %>% 
  count(week) %>% 
  ggplot(aes(x = week, y = n)) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = "loess", span = 0.2) +
  #First UK case
  geom_vline(xintercept = as.Date("2020-01-23"), linetype = "33") +
  # First UK lockdown begins
  geom_vline(xintercept = as.Date("2020-03-23"), linetype = "12") +
  #First UK lockdown ends
  geom_vline(xintercept = as.Date("2020-06-01"), linetype = "42") +
  scale_x_date(date_breaks = "6 months", date_labels = "%b\n%Y", 
               limits = as.Date(c("2015-01-01", "2020-12-31"))) +
  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +
  labs(
      title = "Missing Incident Trend: 2015:2020",
      x = NULL,
      y = "weekly count", 
      caption = "1:First UK case,
                 2:First UK lockdown begins,
                 3:First UK lockdown ends"
    ) +
  theme_minimal()


covid %>%
  mutate(week = as_date(yearweek(incident_date_time))) %>% 
  count(week) %>% 
  ggplot(aes(x = week, y = n)) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = "loess", span = 0.2) +
  #First UK case
  geom_vline(xintercept = as.Date("2020-01-23"), linetype = "33") +
  # First UK lockdown begins
  geom_vline(xintercept = as.Date("2020-03-23"), linetype = "12") +
  #First UK lockdown ends
  geom_vline(xintercept = as.Date("2020-06-01"), linetype = "42") +
  scale_x_date(date_breaks = "1 months", date_labels = "%b\n%Y") +
  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +
  labs(
      title = "Missing Incident Trend: 2015:2020",
      x = NULL,
      y = "weekly count", 
      caption = "1:First UK case,
                 2:First UK lockdown begins,
                 3:First UK lockdown ends"
    ) +
  theme_minimal()

```




## trends and seaonality - with covid dates


```{r}
#monlty trends
calls_per_year <- missing %>%
  mutate(month = as_date(yearmonth(incident_date_time))) %>%
  group_by(month) %>%
  summarise(count=n())

#turn to ts 
df <- ts(data = calls_per_year$count, frequency = 12, start = c(2015, 1))
df

#seaonal plot 
ggseasonplot(df, year.labels = TRUE, year.labels.left = TRUE) + 
  ylab("count") + 
  ggtitle("Seasonal Plot: Mising Incidents")

ggseasonplot(df, polar = TRUE) + 
  ylab("count") + 
  ggtitle("Polar Seasonal Plot: Mising Incidents")

#Seaonal sub series 
ggsubseriesplot(df) + 
  ylab("count") + 
  ggtitle("Subseries Seasonal Plot: Mising Incidents 2015-2020") # horizontal lines = means for each month 


##lag plots 
gglagplot(df)


#autocorrelation - measures the linear relationship betwen lagged values of a time series (acf)
ggAcf(df)
#lag3 s the highest due to the seaonal pattern in the data


## TREND and seasonality in ACF plots 
df

autoplot(df) + xlab("month") + ylab("count") + 
  ggtitle("Trend and Seasonality of ACF") 

#When data have a trend, the autocorrelations for small lags tend to be large and positive because observations nearby in time are also nearby in size. So the ACF of trended time series tend to have positive values that slowly decrease as the lags increase.

#When data are seasonal, the autocorrelations will be larger for the seasonal lags (at multiples of the seasonal frequency) than for other lags.

# in this instanc, hard to declare both trend and seasonality 
ggAcf(df, lag=48) + 
  ggtitle("ACF of monthly missing incident count (2015:2020)")
#arguabl slow decrease in the ACF as the lags increase is due tot h trend, but not clear 'scalloped' shape for seasonality 


##White nose - time series with no autocorrelation (what we see in autoplot) - however If one or more large spikes are outside these bounds, or if substantially more than 5% of spikes are outside these bounds, then the series is probably not white noise


```





## trends and seaonality - without covid 2015-2019


```{r}
#monlty trends
calls_per_month <- missing %>%
  mutate(month = as_date(yearmonth(incident_date_time))) %>%
  group_by(month) %>%
  summarise(count=n())

#turn to ts 
df <- ts(data = calls_per_month$count, frequency = 12, start = c(2015, 1))
df

df2 <- ts(data = calls_per_month$count, frequency = 12, start = c(2015, 1), end = c(2019, 12))
df2

df3 <- ts(data = calls_per_month$count, frequency = 12, start = c(2020, 1), end = c(2020, 12))
df3


#seaonal plot 
ggseasonplot(df2, year.labels = TRUE, year.labels.left = TRUE) + 
  ylab("count") + 
  ggtitle("Seasonal Plot: Mising Incidents")

ggseasonplot(df2, polar = TRUE) + 
  ylab("count") + 
  ggtitle("Polar Seasonal Plot: Mising Incidents")

#Seaonal sub series 
ggsubseriesplot(df2) + 
  ylab("count") + 
  ggtitle("Subseries Seasonal Plot: 2015-2019") # horizontal lines = means for each month 


##lag plots 
gglagplot(df2)


#autocorrelation - measures the linear relationship betwen lagged values of a time series (acf)
ggAcf(df2)
#lag3 s the highest due to the seaonal pattern in the data


## TREND and seasonality in ACF plots 
df2

autoplot(df2) + xlab("month") + ylab("count") + 
  ggtitle("Trend and Seasonality of ACF") 

#When data have a trend, the autocorrelations for small lags tend to be large and positive because observations nearby in time are also nearby in size. So the ACF of trended time series tend to have positive values that slowly decrease as the lags increase.

#When data are seasonal, the autocorrelations will be larger for the seasonal lags (at multiples of the seasonal frequency) than for other lags.

# in this instanc, hard to declare both trend and seasonality 
ggAcf(df2, lag=48) + 
  ggtitle("ACF of monthly missing incident count (2015:2019)")
#arguabl slow decrease in the ACF as the lags increase is due tot h trend, but not clear 'scalloped' shape for seasonality 


##White nose - time series with no autocorrelation (what we see in autoplot) - however If one or more large spikes are outside these bounds, or if substantially more than 5% of spikes are outside these bounds, then the series is probably not white noise


```







## time series decompoistions - 

```{r}
#a trend-cycle component, a seasonal component, and a remainder component (containing anything else in the time series).

## moving averages to examine trend-cycle 
ma(df, 12)  # 12 months in a year

autoplot(df, series="Data") +
  autolayer(ma(df,12), series="12-MA") +
  xlab("month") + ylab("count") +
  ggtitle("Annual Missing Incident Trend (2015:2020)", 
          subtitle = "Trend-Cycle with 12-MA plotted against original Data") +
  scale_colour_manual(values=c("Data"="grey50","12-MA"="red"),
                      breaks=c("Data","12-MA"))

#without covid dates
autoplot(df2, series="Data") +
  autolayer(ma(df2,12), series="12-MA") +
  xlab("month") + ylab("count") +
  ggtitle("Annual Missing Incident Trend (2015:2019)", 
          subtitle = "Trend-Cycle with 12-MA plotted against original Data") +
  scale_colour_manual(values=c("Data"="grey50","12-MA"="red"),
                      breaks=c("Data","12-MA"))


### used for estimating the trend-cycle from seasonal data

#Notice that the trend-cycle (in red) is smoother than the original data and captures the main movement of the time series without all of the minor fluctuations. 

## use moving averages of moving averages in order to make an even-order moving average symmetric 
df
ma4 <- ma(df, order = 4, centre = FALSE)
ma2x4 <- ma(df, order=4, centre=TRUE)
ma2x4

autoplot(df, series="Data") +
  autolayer(ma(df,12), series="12-MA") +
  xlab("Month") + ylab("Count") +
  ggtitle("Annual Missing Incident Trend", 
          subtitle = "2*12-MA") +
  scale_colour_manual(values=c("Data"="grey50","12-MA"="red"),
                      breaks=c("Data","12-MA"))

#this shows a 2*12 MA applied to the missing incident counts - the smooth line shows no seaonslity 


## decompoisiton (x11 or ATL) 

#x11
#trend-cycle estimates are available for all observations including the end points, and the seasonal component is allowed to vary slowly over time. 
#It handles both additive and multiplicative decomposition. The process is entirely automatic and tends to be highly robust to outliers and level shifts in the time series



## full dataset vs without covid 

library(seasonal)

df %>% seas(x11="") -> fit
autoplot(fit) +
  ggtitle("X11 Decomposition of Missing Incidents (2015:2020)")


# highlight the trend-cycle component and the seasonaly adjusted data, compared to original data 
autoplot(df, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Month") + ylab("Count") +
  ggtitle("Incident Count 2015:2020") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend")) + 
   theme(legend.position="bottom") +
  theme(legend.title = element_text(colour = "white", size = 15, face = "bold"))


## examine the seasonal plots and sub-series plots of the seasonal component 
fit %>% seasonal() %>% ggsubseriesplot() + ylab("Seasonal") + 
  ggtitle("Variation in Seasonal Componentfrom 2015:2020", 
          subtitle = "Seasonal sub-series of the seasonal component from the X11 decomposition")
# visualise the variation in the seasonal component over time. 


#############

df2 %>% seas(x11="") -> fit1
autoplot(fit1) +
  ggtitle("X11 Decomposition of Missing Incidents (2015:2019)")


# highlight the trend-cycle component and the seasonaly adjusted data, compared to original data 
autoplot(df2, series ="Data") +
  autolayer(trendcycle(fit1), series="Trend") +
  autolayer(seasadj(fit1), series="Seasonally Adjusted") +
  xlab("Month") + ylab("Count") +
  ggtitle("Incident Count 2015:2019") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend")) +
  theme(legend.position="bottom") + 
  theme(legend.title = element_text(colour = "white", size = 15, face = "bold"))
             

             
## examine the seasonal plots and sub-series plots of the seasonal component 
fit1 %>% seasonal() %>% ggsubseriesplot() + ylab("Seasonal") + 
  ggtitle("Variation in Seasonal Component from 2015:2019", 
          "Seasonal sub-series of the seasonal component from the X11 decomposition")
# visualise the variation in the seasonal component over time. 




```





## Forecasting with decomposition 

```{r}
#To forecast a decomposed time series, we forecast the seasonal component,and the seasonally adjusted component  separately. It is usually assumed that the seasonal component is unchanging, or changing extremely slowly, so it is forecast by simply taking the last year of the estimated component. In other words, a seasonal naïve method is used for the seasonal component.

#naive forecasts of seasonally adjusted data 
fit <- stl(df, t.window=13, s.window="periodic",
  robust=TRUE)
fit %>% seasadj() %>% naive() %>%
  autoplot() + ylab("New orders index") +
  ggtitle("Naive forecasts of seasonally adjusted data")


fit %>% forecast(method="naive") %>%
  autoplot() + ylab("New orders index")


# That is, the upper and lower limits of the prediction intervals on the seasonally adjusted data are “reseasonalised” by adding in the forecasts of the seasonal component. 
```






## ARIMA model

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, echo = FALSE, include = TRUE)

library(lubridate)
library(tidyverse)
library(tsibble)
```

```{r}

#call_forecasts <- read_rds(here::here("output/call_forecasts.Rds"))
call_forecasts <- read_rds("Z:\\call_forecasts.Rds") 

# Note important dates
# Source: https://www.instituteforgovernment.org.uk/sites/default/files/timeline-lockdown-web.pdf
dates <- tribble(
  ~date, ~event,
  "2020-01-31", "first UK COVID case",
  "2020-03-23", "first lockdown begins",
  "2020-06-15", "first lockdown ends",
  "2020-09-22", "new restrictions; WfH and 10pm curfew", 
  "2020-10-14", "New Tier System",
  "2020-11-05", "second lockdown begins",
  "2020-12-02", "second lockdown ends", 
  "2020-12-31", "Tier 4 for Cheshire"
) %>% 
  mutate(
    date = as_date(yearweek(ymd(date))), 
    row = row_number(),
    label = str_glue("{row}. {event}")
  )
```

```{r create chart function, include=FALSE}
forecast_chart <- function (forecasts, types) {
  
  forecasts %>% 
    filter(incident_type_new %in% types) %>% 
    # Occasionally the ARIMA model may produce forecast confidence intervals
    # that are less than zero, which will not show up on the plot because we
    # have set the y axis to start at zero (to make changes in vertical position
    # on the axis representative of changes in magnitude). To deal with this we
    # will manually set the lower CI of the forecasts to be zero if it is less
    # than zero in the original forecast.
    mutate(forecast_lower = ifelse(forecast_lower < 0, 0, forecast_lower)) %>% 
    ggplot() +
    # Forecast
    geom_ribbon(
      aes(incident_week, ymin = forecast_lower, ymax = forecast_upper), 
      na.rm = TRUE,
      alpha = 0.5, 
      fill = "grey80"
    ) +
    geom_line(aes(incident_week, forecast_mean), na.rm = TRUE, linetype = "22") +
    # Dates of interest
    geom_vline(aes(xintercept = date), data = dates, linetype = "12") +
    geom_label(aes(date, 0, label = row), data = dates, colour = "grey20") +
    # Actual calls
    geom_line(aes(incident_week, actual_calls)) +
    geom_point(aes(incident_week, actual_calls, fill = sig), shape = 21) +
    scale_x_date(date_labels = "%e %b\n%Y", 
                 limits = as.Date(c("2020-01-06", "2020-12-21"))) +
    scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +
    scale_fill_manual(values = c(`TRUE` = "black", `FALSE` = "grey80")) +
    labs(
      title = "Calls for service during 2021 compared to pre-pandemic forecast",
      subtitle = str_wrap(
        str_glue("Events by week: ", str_c(pull(dates, label), collapse = "; ")), 
        80
      ),
      caption = "Forecast calculated using data up to 31 January 2020",
      x = NULL,
      y = "weekly count of calls for service",
      fill = "actual calls significantly different from forecast"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom", plot.title = element_text(face = "bold"))
  
}
```

```{r Missing Person}
forecast_chart(call_forecasts, "Missing Person")
```

Significant differences again following the first lockdown. Supported by literature with more children being at home and less opportunity for 'juvenile runaways'.








## Stationarity and differencing


Stationary data: no clear trend or seasonality i.e. no predictable pattern (white noise)
Non-stationary: in the data there are some trends, increasing variance, some seasonality 
differencing: making the data non-stationary data stationary 

models for non-stationary data: 
  - random walk
  - second order differencing 
  - seasonal differencing 


```{r seasonal differencing}
cbind("Count" = df,
      "Monthly Count" = log(df),
      "Annual change in log sales" = diff(log(df),12)) %>%
  autoplot(facets=TRUE) +
    xlab("Year") + ylab("") +
    ggtitle("Missing Incidents")
```


even with this tranformation, this data doesnt look to appear stationary so we can try to use both a seasonal difference and a first difference to obtain stationary data 


```{r}
cbind("Count" = df,
      "Logs" = log(df),
      "Seasonally\n differenced logs" =
        diff(log(df),12),
      "Doubly\n differenced logs" =
        diff(diff(log(df),12),1)) %>%
  autoplot(facets=TRUE) +
    xlab("month") + ylab("") +
    ggtitle("Monthly Count")
```



unit root test to decided whether differencing is required 

```{r}
library(urca)
df %>% ur.kpss() %>% summary()

#The test statistic is much bigger than the 1% critical value (0.68), indicating that the null hypothesis is rejected. That is, the data are not stationary. 

#We can difference the data, and apply the test again.

df %>% diff() %>% ur.kpss() %>% summary()

#test = 0.08 


ndiffs(df)
# = 1
# one difference is required to make the data stationary 


nsdiffs(df)
# = 0
#As Fs < 0.64 (0) one seasonal difference is suggested 

```


## auto-arima 

```{r}
fit <- auto.arima(df, seasonal=FALSE)
fit
#Arima(1,1,1) , AR, frst differnce and MA
#the ar coeffecient is statistically siginificant (z = 0.59/0.18 = 0.38)
#however, the ma1 coeffieficnt is not siginficant as its less 0 (-7.425) and less than 1,96 n absolute value 
fit %>% forecast(h=10) %>% autoplot(include=80)
```


# check the acf pacf


```{r}
ggAcf(df)
ggPacf(df)
```

both acf and pacf start at lag 1


#Arima 1,1

```{r}
(fit2 <- Arima(df, order=c(1,1,0)))
```











